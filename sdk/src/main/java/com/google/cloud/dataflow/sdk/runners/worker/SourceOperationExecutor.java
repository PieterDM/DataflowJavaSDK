/*******************************************************************************
 * Copyright (C) 2015 Google Inc.
 *
 * Licensed under the Apache License, Version 2.0 (the "License"); you may not
 * use this file except in compliance with the License. You may obtain a copy of
 * the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
 * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
 * License for the specific language governing permissions and limitations under
 * the License.
 ******************************************************************************/

package com.google.cloud.dataflow.sdk.runners.worker;

import static com.google.cloud.dataflow.sdk.runners.worker.SourceTranslationUtils.cloudSourceOperationRequestToSourceOperationRequest;
import static com.google.cloud.dataflow.sdk.runners.worker.SourceTranslationUtils.sourceOperationResponseToCloudSourceOperationResponse;

import com.google.api.services.dataflow.model.Source;
import com.google.api.services.dataflow.model.SourceOperationRequest;
import com.google.api.services.dataflow.model.SourceOperationResponse;
import com.google.api.services.dataflow.model.SourceSplitResponse;
import com.google.cloud.dataflow.sdk.options.PipelineOptions;
import com.google.cloud.dataflow.sdk.runners.worker.SourceTranslationUtils.DataflowSourceOperationResponse;
import com.google.cloud.dataflow.sdk.util.common.CounterSet;
import com.google.cloud.dataflow.sdk.util.common.worker.MapTaskExecutor;
import com.google.cloud.dataflow.sdk.util.common.worker.SourceFormat;
import com.google.cloud.dataflow.sdk.util.common.worker.WorkExecutor;

import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.io.IOException;

/**
 * An executor for a source operation, defined by a {@code SourceOperationRequest}.
 */
@SuppressWarnings("resource")
public class SourceOperationExecutor extends WorkExecutor {
  private static final Logger LOG = LoggerFactory.getLogger(MapTaskExecutor.class);
  public static final String SPLIT_RESPONSE_TOO_LARGE_ERROR =
      "Total size of the BoundedSource objects generated by splitIntoBundles() operation is larger"
      + " than the allowable limit. For more information, please check the corresponding FAQ"
      + " entry at :\n"
      + "https://cloud.google.com/dataflow/faq";
  // This limit is only used to produce an error message. Actual current limit offered by the
  // service may be different.
  private static final int SOURCE_OPERATION_RESPONSE_SIZE_LIMIT_MB = 20;

  private final PipelineOptions options;
  private final SourceOperationRequest request;
  private SourceOperationResponse response;

  public SourceOperationExecutor(PipelineOptions options,
                                 SourceOperationRequest request,
                                 CounterSet counters) {
    super(counters);
    this.options = options;
    this.request = request;
  }

  @Override
  public void execute() throws Exception {
    LOG.debug("Executing source operation");

    Source sourceSpec;
    if (request.getGetMetadata() != null) {
      sourceSpec = request.getGetMetadata().getSource();
    } else if (request.getSplit() != null) {
      sourceSpec = request.getSplit().getSource();
    } else {
      throw new UnsupportedOperationException("Unknown source operation");
    }

    this.response = sourceOperationResponseToCloudSourceOperationResponse(
        SourceFormatFactory.create(options, sourceSpec)
            .performSourceOperation(
                cloudSourceOperationRequestToSourceOperationRequest(request)));

    LOG.debug("Source operation execution complete");
  }

  public SourceOperationResponse getResponse() {
    return response;
  }

  static boolean isSplitResponseTooLarge(SourceFormat.OperationResponse operationResponse) {
    return isSplitOperationResponse(operationResponse)
        && isSplitOperationTooLargeForDataflowService(operationResponse);
  }

  private static boolean isSplitOperationTooLargeForDataflowService(
      SourceFormat.OperationResponse operationResponse) {
    try {
      SourceSplitResponse splitResponse =
          ((DataflowSourceOperationResponse) operationResponse).cloudResponse.getSplit();
      int size = splitResponse.getFactory().toByteArray(operationResponse).length;
      return size >= SOURCE_OPERATION_RESPONSE_SIZE_LIMIT_MB * 1024 * 1024;
    } catch (OutOfMemoryError e) {
      LOG.error("Got exception when trying to serialize split response: " + e.getMessage());
      // We will go out of memory if split response is extremely large.
      return true;
    } catch (IOException e) {
      throw new RuntimeException(e);
    }
  }

  private static boolean isSplitOperationResponse(
      SourceFormat.OperationResponse operationResponse) {
    if (operationResponse instanceof DataflowSourceOperationResponse) {
      return (
          ((DataflowSourceOperationResponse) operationResponse).cloudResponse.getSplit() != null);
    }

    return false;
  }
}
